<tool id="pp.dca" name="pp.dca" version="1.3.1+galaxy1">
  <description>Deep count autoencoder [Eraslan18]_.</description>
  <macros>
    <import>macros.xml</import>
  </macros>
  <expand macro="requirements"/>
  <command detect_errors="exit_code"><![CDATA[
        python $script_file
    ]]></command>
  <configfiles>
    <configfile name="script_file"><![CDATA[
import scanpy.api as sc

@CMD_read_inputs

sc.pp.dca(
   adata = '$adata',
   mode = '$mode',
   ae_type = '$ae_type',
   normalize_per_cell = '$normalize_per_cell',
   scale = '$scale',
   log1p = '$log1p',
   hidden_size = '$hidden_size',
   hidden_dropout = '$hidden_dropout',
   batchnorm = '$batchnorm',
   activation = '$activation',
   init = '$init',
   network_kwds = '$network_kwds',
   epochs = '$epochs',
   reduce_lr = '$reduce_lr',
   early_stop = '$early_stop',
   batch_size = '$batch_size',
   optimizer = '$optimizer',
   random_state = '$random_state',
   threads = '$threads',
   verbose = '$verbose',
   training_kwds = '$training_kwds',
   return_model = '$return_model',
   return_info = '$return_info',
   copy = '$copy',)

adata.write_loom($csv_output)
adata.write_csv($loom_output)
]]></configfile>
  </configfiles>
  <inputs>
    <expand macro="inputs_anndata"/>
    <param name="mode" type="str" value="" optional="true" label="mode" help="    `denoise` overwrites `adata.X` with denoised expression values.    In `latent` mode DCA adds `adata.obsm['X_dca']` to given adata    object. This matrix represent latent representation of cells via DCA."/>
    <param name="ae_type" type="str" value="" optional="true" label="ae_type" help="    Type of the autoencoder. Return values and the architecture is    determined by the type e.g. `nb` does not provide dropout    probabilities. Types that end with &quot;-conddisp&quot;, assumes that dispersion is mean dependant."/>
    <param name="normalize_per_cell" type="bool" value="" optional="true" label="normalize_per_cell" help="    If true, library size normalization is performed using    the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata    object. Mean layer is re-introduces library size differences by    scaling the mean value of each cell in the output layer. See the    manuscript for more details."/>
    <param name="scale" type="bool" value="" optional="true" label="scale" help="    If true, the input of the autoencoder is centered using    `sc.pp.scale` function of Scanpy. Note that the output is kept as raw    counts as loss functions are designed for the count data."/>
    <param name="log1p" type="bool" value="" optional="true" label="log1p" help="    If true, the input of the autoencoder is log transformed with a    pseudocount of one using `sc.pp.log1p` function of Scanpy."/>
    <param name="hidden_size" type="tuple" value="" optional="true" label="hidden_size" help="    Width of hidden layers."/>
    <param name="hidden_dropout" type="float" value="" optional="true" label="hidden_dropout" help="    Probability of weight dropout in the autoencoder (per layer if list    or tuple)."/>
    <param name="batchnorm" type="bool" value="" optional="true" label="batchnorm" help="    If true, batch normalization is performed."/>
    <param name="activation" type="str" value="" optional="true" label="activation" help="    Activation function of hidden layers."/>
    <param name="init" type="str" value="" optional="true" label="init" help="    Initialization method used to initialize weights."/>
    <param name="network_kwds" type="dict" value="" optional="true" label="network_kwds" help="    Additional keyword arguments for the autoencoder."/>
    <param name="epochs" type="int" value="" optional="true" label="epochs" help="    Number of total epochs in training."/>
    <param name="reduce_lr" type="int" value="" optional="true" label="reduce_lr" help="    Reduces learning rate if validation loss does not improve in given number of epochs."/>
    <param name="early_stop" type="int" value="" optional="true" label="early_stop" help="    Stops training if validation loss does not improve in given number of epochs."/>
    <param name="batch_size" type="int" value="" optional="true" label="batch_size" help="    Number of samples in the batch used for SGD."/>
    <param name="optimizer" type="str" value="" optional="true" label="optimizer" help="    Type of optimization method used for training."/>
    <param name="random_state" type="int" value="" optional="true" label="random_state" help="    Seed for python, numpy and tensorflow."/>
    <param name="threads" type="int" value="" optional="true" label="threads" help="    Number of threads to use in training. All cores are used by default."/>
    <param name="verbose" type="bool" value="" optional="true" label="verbose" help="    If true, prints additional information about training and architecture."/>
    <param name="training_kwds" type="dict" value="" optional="true" label="training_kwds" help="    Additional keyword arguments for the training process."/>
    <param name="return_model" type="bool" value="" optional="true" label="return_model" help="    If true, trained autoencoder object is returned. See &quot;Returns&quot;."/>
    <param name="return_info" type="bool" value="" optional="true" label="return_info" help="    If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout    probabilities (obsm['X_dca_dropout']) and estimated dispersion values    (obsm['X_dca_dispersion']), in case that autoencoder is of type    zinb or zinb-conddisp."/>
    <param name="copy" type="bool" value="" optional="true" label="copy" help="    If true, a copy of anndata is returned."/>
    </inputs>
  <outputs>
    <data name="If `copy` is true and `return_model` is false, AnnData object is returned." type="data" format="" label="${tool.name} on ${on_string}: If `copy` is true and `return_model` is false, AnnData object is returned."/>
    <data name="csv_output" type="data" format="csv" label="${tool.name} on ${on_string}: Annotated matrix (csv)"/>
    <data name="If `return_info` is true, all estimated distribution parameters are stored in AnnData such as:" type="data" format="" label="${tool.name} on ${on_string}: If `return_info` is true, all estimated distribution parameters are stored in AnnData such as:"/>
    <data name="- `.obsm[&quot;X_dca_dropout&quot;]` which is the mixture coefficient (pi) of the zero component    in ZINB, i.e. dropout probability (only if `ae_type` is `zinb` or `zinb-conddisp`)." type="data" format="" label="${tool.name} on ${on_string}: - `.obsm[&quot;X_dca_dropout&quot;]` which is the mixture coefficient (pi) of the zero component    in ZINB, i.e. dropout probability (only if `ae_type` is `zinb` or `zinb-conddisp`)."/>
    <data name="- `.obsm[&quot;X_dca_dispersion&quot;]` which is the dispersion parameter of NB." type="data" format="" label="${tool.name} on ${on_string}: - `.obsm[&quot;X_dca_dispersion&quot;]` which is the dispersion parameter of NB."/>
    <data name="- `.uns[&quot;dca_loss_history&quot;]` which stores the loss history of the training. See `.history`    attribute of Keras History class for mode details." type="data" format="" label="${tool.name} on ${on_string}: - `.uns[&quot;dca_loss_history&quot;]` which stores the loss history of the training. See `.history`    attribute of Keras History class for mode details."/>
    <data name="Finally, the raw counts are stored in `.raw` attribute of AnnData object." type="data" format="" label="${tool.name} on ${on_string}: Finally, the raw counts are stored in `.raw` attribute of AnnData object."/>
    <data name="If `return_model` is given, trained model is returned. When both `copy` and `return_model`    are true, a tuple of anndata and model is returned in that order." type="data" format="" label="${tool.name} on ${on_string}: If `return_model` is given, trained model is returned. When both `copy` and `return_model`    are true, a tuple of anndata and model is returned in that order."/>
    <data name="loom_output" type="data" format="loom" label="${tool.name} on ${on_string}: Annotated matrix (loom)"/>
    </outputs>
  <tests>
    <test>
      <param name="mode" value=""/>
      <param name="ae_type" value=""/>
      <param name="normalize_per_cell" value=""/>
      <param name="scale" value=""/>
      <param name="log1p" value=""/>
      <param name="hidden_size" value=""/>
      <param name="hidden_dropout" value=""/>
      <param name="batchnorm" value=""/>
      <param name="activation" value=""/>
      <param name="init" value=""/>
      <param name="network_kwds" value=""/>
      <param name="epochs" value=""/>
      <param name="reduce_lr" value=""/>
      <param name="early_stop" value=""/>
      <param name="batch_size" value=""/>
      <param name="optimizer" value=""/>
      <param name="random_state" value=""/>
      <param name="threads" value=""/>
      <param name="verbose" value=""/>
      <param name="training_kwds" value=""/>
      <param name="return_model" value=""/>
      <param name="return_info" value=""/>
      <param name="copy" value=""/>
      <output name="If `copy` is true and `return_model` is false, AnnData object is returned." file=""/>
      <output name="loom_output" file=""/>
      <output name="csv_output" file=""/>
      <output name="If `return_info` is true, all estimated distribution parameters are stored in AnnData such as:" file=""/>
      <output name="- `.obsm[&quot;X_dca_dropout&quot;]` which is the mixture coefficient (pi) of the zero component    in ZINB, i.e. dropout probability (only if `ae_type` is `zinb` or `zinb-conddisp`)." file=""/>
      <output name="- `.obsm[&quot;X_dca_dispersion&quot;]` which is the dispersion parameter of NB." file=""/>
      <output name="- `.uns[&quot;dca_loss_history&quot;]` which stores the loss history of the training. See `.history`    attribute of Keras History class for mode details." file=""/>
      <output name="Finally, the raw counts are stored in `.raw` attribute of AnnData object." file=""/>
      <output name="If `return_model` is given, trained model is returned. When both `copy` and `return_model`    are true, a tuple of anndata and model is returned in that order." file=""/>
      <output name="loom_output" file=""/>
    </test>
  </tests>
  <help><![CDATA[
        Deep count autoencoder [Eraslan18]_.

Fits a count autoencoder to the raw count data given in the anndata object
in order to denoise the data and to capture hidden representation of
cells in low dimensions. Type of the autoencoder and return values are
determined by the parameters.

More information and bug reports `here <https://github.com/theislab/dca>`__.

Parameters
----------
adata : :class:`~anndata.AnnData`
    An anndata file with `.raw` attribute representing raw counts.
mode : `str`, optional. `denoise`(default), or `latent`.
    `denoise` overwrites `adata.X` with denoised expression values.
    In `latent` mode DCA adds `adata.obsm['X_dca']` to given adata
    object. This matrix represent latent representation of cells via DCA.
ae_type : `str`, optional. `zinb-conddisp`(default), `zinb`, `nb-conddisp` or `nb`.
    Type of the autoencoder. Return values and the architecture is
    determined by the type e.g. `nb` does not provide dropout
    probabilities. Types that end with "-conddisp", assumes that dispersion is mean dependant.
normalize_per_cell : `bool`, optional. Default: `True`.
    If true, library size normalization is performed using
    the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata
    object. Mean layer is re-introduces library size differences by
    scaling the mean value of each cell in the output layer. See the
    manuscript for more details.
scale : `bool`, optional. Default: `True`.
    If true, the input of the autoencoder is centered using
    `sc.pp.scale` function of Scanpy. Note that the output is kept as raw
    counts as loss functions are designed for the count data.
log1p : `bool`, optional. Default: `True`.
    If true, the input of the autoencoder is log transformed with a
    pseudocount of one using `sc.pp.log1p` function of Scanpy.
hidden_size : `tuple` or `list`, optional. Default: (64, 32, 64).
    Width of hidden layers.
hidden_dropout : `float`, `tuple` or `list`, optional. Default: 0.0.
    Probability of weight dropout in the autoencoder (per layer if list
    or tuple).
batchnorm : `bool`, optional. Default: `True`.
    If true, batch normalization is performed.
activation : `str`, optional. Default: `relu`.
    Activation function of hidden layers.
init : `str`, optional. Default: `glorot_uniform`.
    Initialization method used to initialize weights.
network_kwds : `dict`, optional.
    Additional keyword arguments for the autoencoder.
epochs : `int`, optional. Default: 300.
    Number of total epochs in training.
reduce_lr : `int`, optional. Default: 10.
    Reduces learning rate if validation loss does not improve in given number of epochs.
early_stop : `int`, optional. Default: 15.
    Stops training if validation loss does not improve in given number of epochs.
batch_size : `int`, optional. Default: 32.
    Number of samples in the batch used for SGD.
optimizer : `str`, optional. Default: "rmsprop".
    Type of optimization method used for training.
random_state : `int`, optional. Default: 0.
    Seed for python, numpy and tensorflow.
threads : `int` or None, optional. Default: None
    Number of threads to use in training. All cores are used by default.
verbose : `bool`, optional. Default: `False`.
    If true, prints additional information about training and architecture.
training_kwds : `dict`, optional.
    Additional keyword arguments for the training process.
return_model : `bool`, optional. Default: `False`.
    If true, trained autoencoder object is returned. See "Returns".
return_info : `bool`, optional. Default: `False`.
    If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout
    probabilities (obsm['X_dca_dropout']) and estimated dispersion values
    (obsm['X_dca_dispersion']), in case that autoencoder is of type
    zinb or zinb-conddisp.
copy : `bool`, optional. Default: `False`.
    If true, a copy of anndata is returned.

Returns
-------
If `copy` is true and `return_model` is false, AnnData object is returned.

In "denoise" mode, `adata.X` is overwritten with the denoised values. In "latent" mode, latent    low dimensional representation of cells are stored in `adata.obsm['X_dca']` and `adata.X`    is not modified. Note that these values are not corrected for library size effects.

If `return_info` is true, all estimated distribution parameters are stored in AnnData such as:

- `.obsm["X_dca_dropout"]` which is the mixture coefficient (pi) of the zero component    in ZINB, i.e. dropout probability (only if `ae_type` is `zinb` or `zinb-conddisp`).

- `.obsm["X_dca_dispersion"]` which is the dispersion parameter of NB.

- `.uns["dca_loss_history"]` which stores the loss history of the training. See `.history`    attribute of Keras History class for mode details.

Finally, the raw counts are stored in `.raw` attribute of AnnData object.

If `return_model` is given, trained model is returned. When both `copy` and `return_model`    are true, a tuple of anndata and model is returned in that order.
    ]]></help>
  <expand macro="citations"/>
</tool>

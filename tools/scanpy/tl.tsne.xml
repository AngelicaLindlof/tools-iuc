<tool id="tl.tsne" name="tl.tsne" version="1.3.1+galaxy1">
  <description>t-SNE [Maaten08]_ [Amir13]_ [Pedregosa11]_.</description>
  <macros>
    <import>macros.xml</import>
  </macros>
  <expand macro="requirements"/>
  <command detect_errors="exit_code"><![CDATA[
        python $script_file
    ]]></command>
  <configfiles>
    <configfile name="script_file"><![CDATA[
import scanpy.api as sc

@CMD_read_inputs

sc.tl.tsne(
   adata = '$adata',
   n_pcs = '$n_pcs',
   use_rep = '$use_rep',
   perplexity = '$perplexity',
   early_exaggeration = '$early_exaggeration',
   learning_rate = '$learning_rate',
   random_state = '$random_state',
   use_fast_tsne = '$use_fast_tsne',
   n_jobs = '$n_jobs',
   copy = '$copy',)

adata.write_loom($csv_output)
adata.write_csv($loom_output)
]]></configfile>
  </configfiles>
  <inputs>
    <expand macro="inputs_anndata"/>
    <param name="n_pcs" type="int" value="None" optional="true" label="n_pcs" help="    Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`."/>
    <param name="use_rep" type="data" format="{`None`" value="None" optional="true" label="use_rep" help="    Use the indicated representation. If `None`, the representation is chosen    automatically: for `.n_vars` &lt; 50, `.X` is used, otherwise 'X_pca' is used.    If 'X_pca' is not present, it's computed with default parameters."/>
    <param name="perplexity" type="float" value="" optional="true" label="perplexity" help="    The perplexity is related to the number of nearest neighbors that    is used in other manifold learning algorithms. Larger datasets    usually require a larger perplexity. Consider selecting a value    between 5 and 50. The choice is not extremely critical since t-SNE    is quite insensitive to this parameter."/>
    <param name="early_exaggeration" type="float" value="" optional="true" label="early_exaggeration" help="    Controls how tight natural clusters in the original space are in the    embedded space and how much space will be between them. For larger    values, the space between natural clusters will be larger in the    embedded space. Again, the choice of this parameter is not very    critical. If the cost function increases during initial optimization,    the early exaggeration factor or the learning rate might be too high."/>
    <param name="learning_rate" type="float" value="" optional="true" label="learning_rate" help="    Note that the R-package &quot;Rtsne&quot; uses a default of 200.    The learning rate can be a critical parameter. It should be    between 100 and 1000. If the cost function increases during initial    optimization, the early exaggeration factor or the learning rate    might be too high. If the cost function gets stuck in a bad local    minimum increasing the learning rate helps sometimes."/>
    <param name="random_state" type="int" value="" optional="true" label="random_state" help="    Change this to use different intial states for the optimization. If `None`,    the initial state is not reproducible."/>
    <param name="use_fast_tsne" type="bool" value="True" optional="true" label="use_fast_tsne" help="    Use the MulticoreTSNE package by D. Ulyanov if it is installed."/>
    <param name="n_jobs" type="int" value="sc.settings.n_jobs" label="n_jobs" help="    Number of jobs."/>
    <param name="copy" type="bool" value="False" label="copy" help="    Return a copy instead of writing to adata."/>
    </inputs>
  <outputs>
    <data name="csv_output" type="data" format="csv" label="${tool.name} on ${on_string}: Annotated matrix (csv)"/>
    <data name="X_tsne" type="np.ndarray" label="${tool.name} on ${on_string}: X_tsne"/>
    <data name="loom_output" type="data" format="loom" label="${tool.name} on ${on_string}: Annotated matrix (loom)"/>
    </outputs>
  <tests>
    <test>
      <param name="n_pcs" value=""/>
      <param name="use_rep" value=""/>
      <param name="perplexity" value=""/>
      <param name="early_exaggeration" value=""/>
      <param name="learning_rate" value=""/>
      <param name="random_state" value=""/>
      <param name="use_fast_tsne" value=""/>
      <param name="n_jobs" value=""/>
      <param name="copy" value=""/>
      <output name="loom_output" file=""/>
      <output name="csv_output" file=""/>
      <output name="X_tsne" file=""/>
      <output name="loom_output" file=""/>
    </test>
  </tests>
  <help><![CDATA[
        t-SNE [Maaten08]_ [Amir13]_ [Pedregosa11]_.

t-distributed stochastic neighborhood embedding (tSNE) [Maaten08]_ has been
proposed for visualizating single-cell data by [Amir13]_. Here, by default,
we use the implementation of *scikit-learn* [Pedregosa11]_. You can achieve
a huge speedup and better convergence if you install `Multicore-tSNE
<https://github.com/DmitryUlyanov/Multicore-TSNE>`__ by [Ulyanov16]_, which
will be automatically detected by Scanpy.

Parameters
----------
adata : :class:`~anndata.AnnData`
    Annotated data matrix.
n_pcs : `int` or `None`, optional (default: `None`)
    Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`.
use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`)
    Use the indicated representation. If `None`, the representation is chosen
    automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used.
    If 'X_pca' is not present, it's computed with default parameters.
perplexity : `float`, optional (default: 30)
    The perplexity is related to the number of nearest neighbors that
    is used in other manifold learning algorithms. Larger datasets
    usually require a larger perplexity. Consider selecting a value
    between 5 and 50. The choice is not extremely critical since t-SNE
    is quite insensitive to this parameter.
early_exaggeration : `float`, optional (default: 12.0)
    Controls how tight natural clusters in the original space are in the
    embedded space and how much space will be between them. For larger
    values, the space between natural clusters will be larger in the
    embedded space. Again, the choice of this parameter is not very
    critical. If the cost function increases during initial optimization,
    the early exaggeration factor or the learning rate might be too high.
learning_rate : `float`, optional (default: 1000)
    Note that the R-package "Rtsne" uses a default of 200.
    The learning rate can be a critical parameter. It should be
    between 100 and 1000. If the cost function increases during initial
    optimization, the early exaggeration factor or the learning rate
    might be too high. If the cost function gets stuck in a bad local
    minimum increasing the learning rate helps sometimes.
random_state : `int` or `None`, optional (default: 0)
    Change this to use different intial states for the optimization. If `None`,
    the initial state is not reproducible.
use_fast_tsne : `bool`, optional (default: `True`)
    Use the MulticoreTSNE package by D. Ulyanov if it is installed.
n_jobs : `int` or `None` (default: `sc.settings.n_jobs`)
    Number of jobs.
copy : `bool` (default: `False`)
    Return a copy instead of writing to adata.

Returns
-------
Depending on `copy`, returns or updates `adata` with the following fields.

X_tsne : `np.ndarray` (`adata.obs`, dtype `float`)
    tSNE coordinates of data.
    ]]></help>
  <expand macro="citations"/>
</tool>

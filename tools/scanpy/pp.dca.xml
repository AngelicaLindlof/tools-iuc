<tool id="pp.dca" name="pp.dca" version="1.3.1+galaxy1">
    <description>Deep count autoencoder</description>
    <macros>
        <import>macros.xml</import>
    </macros>
    <expand macro="requirements">
        <requirement type="package" version="2.0.10">dca</requirement>
        <requirement type="package" version="0.2.8.2">dill</requirement>
    </expand>
    <command detect_errors="exit_code"><![CDATA[
            python $script_file
        ]]></command>
    <configfiles>
        <configfile name="script_file"><![CDATA[
@CMD_imports@
@CMD_read_inputs@

sc.pp.dca(
   adata=adata,
   mode='$mode',
   ae_type='$ae_type',
   normalize_per_cell=$normalize_per_cell,
   scale=$scale,
   log1p=$log1p,
   #if $hidden_size
   hidden_size=$hidden_size,
   #end if
   hidden_dropout=$hidden_dropout,
   batchnorm=$batchnorm,
   activation='$activation',
   init='$init',
   epochs=$epochs,
   reduce_lr=$reduce_lr,
   early_stop=$early_stop,
   batch_size=$batch_size,
   optimizer='$optimizer',
   random_state=$random_state,
   threads=\${GALAXY_SLOTS:-2},
   return_model=True,
   return_info=True,
   copy=False)

@CMD_anndata_write_outputs@
]]></configfile>
    </configfiles>
    <inputs>
        <expand macro="inputs_anndata"/>
        <param name="mode" type="select" label="Mode" help="`denoise` overwrites `adata.X` with denoised expression values. In `latent` mode DCA adds `adata.obsm['X_dca']` to given adata object. This matrix represent latent representation of cells via DCA.">
            <option value="denoise">denoise</option>
            <option value="latent">latent</option>
        </param>
        <param name="ae_type" type="select" optional="true" label="Type of the autoencoder" help="Return values and the architecture is determined by the type e.g. `nb` does not provide dropout probabilities. Types that end with '-conddisp', assumes that dispersion is mean dependant.">
            <option value="zinb">zinb</option>
            <option value="zinb-conddisp" selected="true">zinb-conddisp</option>
            <option value="nb">nb</option>
            <option value="nb-conddisp" selected="true">nb-conddisp</option>
        </param>
        <param name="normalize_per_cell" type="boolean" truevalue="True" falsevalue="False" checked="true" label="Normalize per cell?" help="If true, library size normalization is performed using the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata object. Mean layer is re-introduces library size differences by scaling the mean value of each cell in the output layer. See the manuscript for more details."/>
        <param name="scale" type="boolean" truevalue="True" falsevalue="False" checked="true" label="Scale?" help="If true, the input of the autoencoder is centered using `sc.pp.scale` function of Scanpy. Note that the output is kept as raw counts as loss functions are designed for the count data."/>
        <param name="log1p" type="boolean" truevalue="True" falsevalue="False" checked="true" label="Log transform?" help="If true, the input of the autoencoder is log transformed with a pseudocount of one using `sc.pp.log1p` function of Scanpy."/>
        <param name="hidden_size" type="integer" value="" optional="true" label="Width of hidden layers" help=""/>
        <param name="hidden_dropout" type="float" value="0.0" multiple="true" label="Probability of weight dropout in the autoencoder (per layer if multiple)" help=""/>
        <param name="batchnorm" type="boolean" truevalue="True" falsevalue="False" checked="true" label="Batch normalization?" help=""/>
        <param name="activation" type="select" label="Activation function of hidden layers" help="">
            <option value="relu">relu</option>
            <option value="selu">selu</option>
            <option value="elu">elu</option>
            <option value="PReLU">PReLU</option>
            <option value="linear">linear</option>
            <option value="LeakyReLU">LeakyReLU</option>
        </param>
        <param name="init" type="select" label="Initialization method used to initialize weight" help="">
            <option value="glorot_uniform">glorot_uniform</option>
        </param>
        <param name="epochs" type="integer" value="300" label="Number of total epochs in training" help=""/>
        <param name="reduce_lr" type="integer" value="10" label="Reduces learning rate if validation loss does not improve in given number of epochs" help=""/>
        <param name="early_stop" type="integer" value="15" label="Stops training if validation loss does not improve in given number of epochs" help=""/>
        <param name="batch_size" type="integer" value="32" label="Number of samples in the batch used for SGDs" help=""/>
        <param name="optimizer" type="select" label="Type of optimization method used for training" help="">
            <option value="rmsprop">rmsprop</option>
        </param>
        <param name="random_state" type="integer" value="0" label="Seed for python, numpy and tensorflows" help=""/>
        <expand macro="anndata_output_format"/>
    </inputs>
    <outputs>
        <expand macro="anndata_outputs"/>
    </outputs>
    <tests>
        <test>
            <conditional name="input">
                <param name="format" value="h5ad" />
                <param name="adata" value="paul15.h5ad" />
            </conditional>
            <param name="mode" value="denoise"/>
            <param name="ae_type" value="zinb-conddisp"/>
            <param name="normalize_per_cell" value="True"/>
            <param name="scale" value="True"/>
            <param name="log1p" value="True"/>
            <param name="hidden_size" value="64, 32, 64"/>
            <param name="hidden_dropout" value="0.0"/>
            <param name="batchnorm" value="True"/>
            <param name="activation" value="relu"/>
            <param name="init" value="glorot_uniform"/>
            <param name="epochs" value="1"/>
            <param name="reduce_lr" value="10"/>
            <param name="early_stop" value="15"/>
            <param name="batch_size" value="32"/>
            <param name="optimizer" value="rmsprop"/>
            <param name="random_state" value="32"/>
            <param name="anndata_output_format" value="h5ad" />
            <output name="anndata_out_h5ad" file="pp.dca.paul15_denoise.h5ad" ftype="h5" compare="sim_size"/>
        </test>
        <test>
            <conditional name="input">
                <param name="format" value="h5ad" />
                <param name="adata" value="paul15.h5ad" />
            </conditional>
            <param name="mode" value="latent"/>
            <param name="ae_type" value="zinb-conddisp"/>
            <param name="normalize_per_cell" value="True"/>
            <param name="scale" value="True"/>
            <param name="log1p" value="True"/>
            <param name="hidden_size" value="64, 32, 64"/>
            <param name="hidden_dropout" value="0.0"/>
            <param name="batchnorm" value="True"/>
            <param name="activation" value="relu"/>
            <param name="init" value="glorot_uniform"/>
            <param name="epochs" value="1"/>
            <param name="reduce_lr" value="10"/>
            <param name="early_stop" value="15"/>
            <param name="batch_size" value="32"/>
            <param name="optimizer" value="rmsprop"/>
            <param name="random_state" value="32"/>
            <param name="anndata_output_format" value="h5ad" />
            <output name="anndata_out_h5ad" file="pp.dca.paul15_latent.h5ad" ftype="h5" compare="sim_size"/>
        </test>
    </tests>
    <help><![CDATA[
Fits a count autoencoder to the raw count data given in the anndata object
in order to denoise the data and to capture hidden representation of
cells in low dimensions. Type of the autoencoder and return values are
determined by the parameters.

More information and bug reports `here <https://github.com/theislab/dca>`__.

Returns
-------

In "denoise" mode, `adata.X` is overwritten with the denoised values. 
In "latent" mode, latent low dimensional representation of cells are stored in `adata.obsm['X_dca']` and `adata.X`    is not modified. Note that these values are not corrected for library size effects.

All estimated distribution parameters are stored in AnnData such as:

- `.obsm["X_dca_dropout"]` which is the mixture coefficient (pi) of the zero component    in ZINB, i.e. dropout probability (only if `ae_type` is `zinb` or `zinb-conddisp`).
- `.obsm["X_dca_dispersion"]` which is the dispersion parameter of NB.
- `.uns["dca_loss_history"]` which stores the loss history of the training. See `.history`    attribute of Keras History class for mode details.

Finally, the raw counts are stored in `.raw` attribute of AnnData object.

More details on the `scanpy documentation
<https://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.dca.html#scanpy.api.pp.dca>`__
    ]]></help>
  <expand macro="citations"/>
</tool>
